{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import skimage.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretrainedmodels\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader and Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {'se_resnext50_32x4d':{\n",
    "                   'input_size': 224,\n",
    "                   'input_mean': [0.485, 0.456, 0.406],\n",
    "                   'input_std' : [0.229, 0.224, 0.225]\n",
    "                    },\n",
    "                 'resnet34':{\n",
    "                   'input_size': 224,\n",
    "                   'input_mean': [0.485, 0.456, 0.406],\n",
    "                   'input_std' : [0.229, 0.224, 0.225]\n",
    "                    },\n",
    "                 'dpn68':{\n",
    "                   'input_size': 224,\n",
    "                   'input_mean': [0.485, 0.456, 0.406],\n",
    "                   'input_std' : [0.229, 0.224, 0.225]\n",
    "                    },\n",
    "                 'nasnetamobile':{\n",
    "                   'input_size': 224,\n",
    "                   'input_mean': [0.5],\n",
    "                   'input_std' : [0.5]\n",
    "                    },\n",
    "                 'bninception':{\n",
    "                   'input_size': 299,\n",
    "                   'input_mean': [0.5],\n",
    "                   'input_std' : [0.5]\n",
    "                    },\n",
    "                 'xception':{\n",
    "                   'input_size': 299,\n",
    "                   'input_mean': [0.5],\n",
    "                   'input_std' : [0.5]\n",
    "                    }\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class AtlasData(Dataset):\n",
    "    def __init__(self, split, train = True, model = 'bninception'):\n",
    "        self.split = split\n",
    "        self.train = train\n",
    "        self.train_str = 'train' if self.train else 'test'\n",
    "        self.text_file = 'data/atlas_{}_split_{}.txt'.format(self.train_str, self.split)\n",
    "        \n",
    "        self.data = [[y for y in x.strip().split(' ')] for x in open(self.text_file, 'r').readlines()]\n",
    "        self.imgs = [x[0] for x in self.data]\n",
    "        self.labels = [[int(p) for p in x[1:]] for x in self.data]\n",
    "        \n",
    "        self.input_size = model_configs[model]['input_size']\n",
    "        self.input_mean = model_configs[model]['input_mean']\n",
    "        self.input_std = model_configs[model]['input_std']\n",
    "        \n",
    "        self.transforms = transforms.Compose([transforms.RandomRotation(180),\n",
    "                                              transforms.Resize(self.input_size),\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize(self.input_mean, self.input_std),\n",
    "                                            ])\n",
    "        \n",
    "    def dump_image(self, i):\n",
    "        image = self.load_image_stack(self.imgs[i])\n",
    "        image_name = \"data/train/{}_{}.png\".format(self.imgs[i], 'stacked')\n",
    "        image.save(image_name)\n",
    "        print(\"Saved\", image_name)\n",
    "\n",
    "    \n",
    "    def load_image_stack(self, image_id):\n",
    "        colors = ['red', 'green', 'blue', 'yellow']\n",
    "        absolute_paths = [\"data/train/{}_{}.png\".format(image_id, color) for color in colors]\n",
    "        \n",
    "        images = [skimage.io.imread(path) for path in absolute_paths]\n",
    "        \n",
    "        image_red = images[0]\n",
    "        image_green = images[1] + (images[3]/2).astype(np.uint8)\n",
    "        image_blue = images[2] + (images[3]/2).astype(np.uint8)\n",
    "        \n",
    "        final_image = np.stack((image_red, image_green, image_blue), -1)\n",
    "        to_display = Image.fromarray(final_image)\n",
    "        return to_display\n",
    "        \n",
    "    def load_image(self, i):\n",
    "        image_id = self.imgs[i]\n",
    "        image_path = \"data/train/{}_{}.png\".format(image_id, 'stacked')\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        return image\n",
    "\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        image = self.load_image(i)\n",
    "        image = self.transforms(image)\n",
    "        \n",
    "        label = self.labels[i]\n",
    "        label_arr = np.zeros(28, dtype = np.float32)\n",
    "        [np.put(label_arr, x, 1) for x in label]\n",
    "        \n",
    "        label_arr = torch.from_numpy(label_arr)\n",
    "        \n",
    "        return image, label_arr, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training bninception\n",
      "inception_3a_double_3x3_reduce_bn.bias\n",
      "inception_5a_pool_proj_bn.weight\n",
      "inception_4d_double_3x3_2_bn.bias\n",
      "inception_4a_pool_proj_bn.weight\n",
      "inception_3a_double_3x3_2_bn.running_mean\n",
      "inception_5a_double_3x3_reduce_bn.weight\n",
      "inception_3a_double_3x3_reduce_bn.weight\n",
      "inception_3b_3x3_reduce_bn.running_mean\n",
      "inception_4e_3x3_reduce_bn.running_var\n",
      "inception_4d_pool_proj_bn.running_mean\n",
      "inception_3a_3x3_reduce_bn.weight\n",
      "inception_4c_1x1_bn.bias\n",
      "conv1_7x7_s2_bn.weight\n",
      "inception_4a_1x1_bn.running_var\n",
      "conv2_3x3_bn.weight\n",
      "inception_3a_pool_proj_bn.weight\n",
      "inception_3b_1x1_bn.running_mean\n",
      "inception_4b_3x3_bn.bias\n",
      "inception_4c_pool_proj_bn.bias\n",
      "inception_3b_double_3x3_2_bn.bias\n",
      "inception_4d_pool_proj_bn.running_var\n",
      "inception_4c_3x3_bn.running_mean\n",
      "inception_5b_3x3_bn.running_mean\n",
      "inception_3a_3x3_reduce_bn.running_var\n",
      "inception_5b_pool_proj_bn.running_var\n",
      "inception_4e_3x3_reduce_bn.running_mean\n",
      "inception_3b_double_3x3_2_bn.weight\n",
      "inception_4c_3x3_bn.bias\n",
      "inception_3a_double_3x3_1_bn.running_mean\n",
      "inception_4b_double_3x3_1_bn.running_var\n",
      "inception_5b_double_3x3_2_bn.running_var\n",
      "inception_4b_3x3_reduce_bn.running_mean\n",
      "inception_3c_double_3x3_1_bn.weight\n",
      "inception_5b_3x3_bn.bias\n",
      "inception_5a_3x3_reduce_bn.running_mean\n",
      "inception_4b_1x1_bn.running_var\n",
      "inception_4a_double_3x3_2_bn.weight\n",
      "inception_3a_double_3x3_2_bn.weight\n",
      "inception_4b_1x1_bn.bias\n",
      "inception_5b_double_3x3_reduce_bn.bias\n",
      "inception_3a_double_3x3_reduce_bn.running_var\n",
      "inception_3a_3x3_reduce_bn.running_mean\n",
      "inception_3a_pool_proj_bn.running_mean\n",
      "inception_4b_3x3_reduce_bn.weight\n",
      "inception_3c_double_3x3_2_bn.running_mean\n",
      "inception_3a_double_3x3_1_bn.bias\n",
      "inception_5b_double_3x3_2_bn.weight\n",
      "inception_5a_double_3x3_2_bn.bias\n",
      "inception_5a_double_3x3_reduce_bn.bias\n",
      "inception_4c_3x3_bn.running_var\n",
      "inception_3b_double_3x3_reduce_bn.running_var\n",
      "inception_4a_double_3x3_1_bn.bias\n",
      "inception_4a_double_3x3_reduce_bn.weight\n",
      "inception_3b_1x1_bn.running_var\n",
      "inception_5b_pool_proj_bn.running_mean\n",
      "inception_5a_3x3_reduce_bn.bias\n",
      "inception_4d_3x3_reduce_bn.weight\n",
      "inception_4b_1x1_bn.weight\n",
      "inception_4d_3x3_bn.running_mean\n",
      "inception_3a_1x1_bn.bias\n",
      "inception_5b_double_3x3_reduce_bn.running_mean\n",
      "inception_5b_double_3x3_2_bn.bias\n",
      "conv2_3x3_bn.running_mean\n",
      "conv2_3x3_reduce_bn.running_var\n",
      "inception_4c_3x3_reduce_bn.bias\n",
      "inception_4d_3x3_reduce_bn.running_mean\n",
      "inception_3c_double_3x3_reduce_bn.running_mean\n",
      "inception_4e_double_3x3_2_bn.weight\n",
      "inception_3c_3x3_bn.bias\n",
      "inception_3b_double_3x3_reduce_bn.bias\n",
      "inception_4e_double_3x3_reduce_bn.bias\n",
      "inception_5b_3x3_reduce_bn.bias\n",
      "inception_4b_pool_proj_bn.running_mean\n",
      "inception_3c_3x3_reduce_bn.weight\n",
      "inception_4a_3x3_bn.weight\n",
      "inception_3a_pool_proj_bn.running_var\n",
      "inception_5a_pool_proj_bn.running_var\n",
      "inception_5b_3x3_reduce_bn.running_mean\n",
      "inception_4a_3x3_reduce_bn.weight\n",
      "inception_4d_3x3_reduce_bn.running_var\n",
      "inception_4c_double_3x3_reduce_bn.weight\n",
      "inception_5b_3x3_reduce_bn.running_var\n",
      "inception_5b_pool_proj_bn.weight\n",
      "inception_3a_pool_proj_bn.bias\n",
      "inception_4c_double_3x3_1_bn.running_mean\n",
      "inception_5b_1x1_bn.running_var\n",
      "inception_4a_pool_proj_bn.bias\n",
      "inception_4d_3x3_bn.bias\n",
      "inception_4e_double_3x3_1_bn.running_mean\n",
      "inception_4a_1x1_bn.running_mean\n",
      "inception_3b_pool_proj_bn.running_var\n",
      "inception_4b_double_3x3_2_bn.bias\n",
      "inception_3a_1x1_bn.running_var\n",
      "inception_4b_double_3x3_2_bn.running_var\n",
      "inception_4d_double_3x3_1_bn.running_var\n",
      "inception_4a_double_3x3_2_bn.running_var\n",
      "inception_5b_3x3_bn.running_var\n",
      "inception_3c_3x3_bn.weight\n",
      "inception_5b_double_3x3_1_bn.weight\n",
      "inception_4c_3x3_bn.weight\n",
      "inception_4d_1x1_bn.running_var\n",
      "inception_5a_double_3x3_1_bn.running_var\n",
      "inception_3a_3x3_reduce_bn.bias\n",
      "inception_4d_1x1_bn.running_mean\n",
      "inception_3a_double_3x3_reduce_bn.running_mean\n",
      "inception_3c_3x3_bn.running_mean\n",
      "inception_4b_double_3x3_reduce_bn.running_var\n",
      "conv2_3x3_bn.bias\n",
      "inception_4a_3x3_reduce_bn.running_var\n",
      "inception_4e_double_3x3_reduce_bn.running_var\n",
      "inception_4d_pool_proj_bn.bias\n",
      "inception_4a_1x1_bn.weight\n",
      "inception_3b_3x3_bn.bias\n",
      "inception_5b_3x3_reduce_bn.weight\n",
      "inception_4b_1x1_bn.running_mean\n",
      "inception_4b_pool_proj_bn.weight\n",
      "inception_4c_1x1_bn.running_mean\n",
      "inception_5a_3x3_reduce_bn.running_var\n",
      "inception_3c_double_3x3_1_bn.running_mean\n",
      "inception_3a_3x3_bn.weight\n",
      "inception_3a_double_3x3_2_bn.running_var\n",
      "inception_4d_double_3x3_1_bn.running_mean\n",
      "inception_3a_3x3_bn.running_var\n",
      "inception_3b_3x3_reduce_bn.running_var\n",
      "inception_4b_pool_proj_bn.running_var\n",
      "inception_5a_double_3x3_2_bn.running_mean\n",
      "inception_3b_3x3_reduce_bn.bias\n",
      "inception_5b_double_3x3_reduce_bn.running_var\n",
      "inception_5b_1x1_bn.weight\n",
      "conv1_7x7_s2_bn.bias\n",
      "inception_4d_double_3x3_reduce_bn.weight\n",
      "inception_5a_double_3x3_2_bn.weight\n",
      "inception_5a_1x1_bn.running_mean\n",
      "inception_3a_3x3_bn.running_mean\n",
      "inception_5a_pool_proj_bn.running_mean\n",
      "inception_3b_3x3_bn.weight\n",
      "inception_4c_double_3x3_1_bn.running_var\n",
      "inception_4d_3x3_bn.weight\n",
      "inception_4e_3x3_bn.weight\n",
      "inception_4d_double_3x3_reduce_bn.running_var\n",
      "inception_4e_double_3x3_1_bn.bias\n",
      "inception_4d_3x3_bn.running_var\n",
      "inception_5b_double_3x3_1_bn.running_mean\n",
      "inception_4a_double_3x3_reduce_bn.running_var\n",
      "inception_4d_double_3x3_reduce_bn.running_mean\n",
      "inception_5a_1x1_bn.weight\n",
      "inception_3c_double_3x3_1_bn.bias\n",
      "inception_4a_3x3_bn.running_mean\n",
      "inception_3a_double_3x3_2_bn.bias\n",
      "inception_3a_double_3x3_1_bn.weight\n",
      "inception_4a_double_3x3_2_bn.running_mean\n",
      "inception_4c_double_3x3_2_bn.running_mean\n",
      "inception_4e_3x3_reduce_bn.weight\n",
      "inception_3b_3x3_bn.running_mean\n",
      "inception_3b_double_3x3_2_bn.running_mean\n",
      "inception_4a_3x3_bn.bias\n",
      "inception_4c_double_3x3_2_bn.weight\n",
      "inception_4d_double_3x3_1_bn.bias\n",
      "inception_4e_double_3x3_1_bn.weight\n",
      "inception_4e_double_3x3_2_bn.bias\n",
      "inception_5a_double_3x3_1_bn.weight\n",
      "inception_4d_double_3x3_2_bn.running_mean\n",
      "inception_4b_3x3_reduce_bn.bias\n",
      "inception_4a_double_3x3_reduce_bn.running_mean\n",
      "inception_3b_double_3x3_reduce_bn.weight\n",
      "inception_3b_pool_proj_bn.bias\n",
      "inception_4c_double_3x3_reduce_bn.running_var\n",
      "inception_5a_3x3_bn.weight\n",
      "inception_3c_double_3x3_2_bn.bias\n",
      "inception_4b_3x3_bn.weight\n",
      "inception_4a_double_3x3_1_bn.weight\n",
      "inception_4c_3x3_reduce_bn.running_mean\n",
      "inception_3b_1x1_bn.weight\n",
      "conv2_3x3_reduce_bn.weight\n",
      "inception_4b_pool_proj_bn.bias\n",
      "inception_4c_1x1_bn.weight\n",
      "inception_3b_3x3_reduce_bn.weight\n",
      "inception_4a_1x1_bn.bias\n",
      "inception_4b_double_3x3_1_bn.running_mean\n",
      "inception_4b_double_3x3_2_bn.running_mean\n",
      "inception_3c_double_3x3_reduce_bn.bias\n",
      "inception_5b_double_3x3_1_bn.running_var\n",
      "inception_4c_double_3x3_1_bn.weight\n",
      "inception_3b_1x1_bn.bias\n",
      "conv2_3x3_reduce_bn.running_mean\n",
      "inception_3a_double_3x3_1_bn.running_var\n",
      "inception_5a_double_3x3_1_bn.running_mean\n",
      "inception_4d_3x3_reduce_bn.bias\n",
      "inception_4a_double_3x3_1_bn.running_var\n",
      "inception_4d_double_3x3_reduce_bn.bias\n",
      "inception_3b_double_3x3_1_bn.weight\n",
      "inception_5b_double_3x3_reduce_bn.weight\n",
      "inception_5b_1x1_bn.running_mean\n",
      "inception_4e_3x3_bn.bias\n",
      "inception_4a_double_3x3_1_bn.running_mean\n",
      "inception_4a_pool_proj_bn.running_var\n",
      "inception_4b_double_3x3_reduce_bn.bias\n",
      "inception_4e_double_3x3_2_bn.running_mean\n",
      "inception_4d_1x1_bn.weight\n",
      "inception_4a_3x3_reduce_bn.running_mean\n",
      "inception_5b_1x1_bn.bias\n",
      "inception_4c_double_3x3_1_bn.bias\n",
      "inception_4e_double_3x3_2_bn.running_var\n",
      "inception_3b_double_3x3_reduce_bn.running_mean\n",
      "inception_4c_double_3x3_reduce_bn.bias\n",
      "inception_4d_double_3x3_2_bn.weight\n",
      "inception_3b_pool_proj_bn.weight\n",
      "inception_3c_double_3x3_1_bn.running_var\n",
      "inception_4a_pool_proj_bn.running_mean\n",
      "inception_5a_3x3_reduce_bn.weight\n",
      "inception_4c_3x3_reduce_bn.running_var\n",
      "conv1_7x7_s2_bn.running_var\n",
      "inception_4e_double_3x3_1_bn.running_var\n",
      "inception_5a_pool_proj_bn.bias\n",
      "inception_3b_3x3_bn.running_var\n",
      "inception_3b_double_3x3_1_bn.bias\n",
      "inception_3c_double_3x3_reduce_bn.running_var\n",
      "inception_5a_double_3x3_reduce_bn.running_var\n",
      "inception_4b_3x3_bn.running_var\n",
      "inception_4e_double_3x3_reduce_bn.weight\n",
      "inception_4d_double_3x3_2_bn.running_var\n",
      "inception_5b_double_3x3_2_bn.running_mean\n",
      "inception_4c_pool_proj_bn.weight\n",
      "inception_4b_double_3x3_2_bn.weight\n",
      "inception_5a_3x3_bn.running_var\n",
      "inception_4a_3x3_reduce_bn.bias\n",
      "inception_4b_3x3_reduce_bn.running_var\n",
      "inception_3b_double_3x3_1_bn.running_mean\n",
      "inception_3c_double_3x3_reduce_bn.weight\n",
      "inception_4c_3x3_reduce_bn.weight\n",
      "conv2_3x3_reduce_bn.bias\n",
      "inception_4c_double_3x3_reduce_bn.running_mean\n",
      "inception_3b_pool_proj_bn.running_mean\n",
      "inception_5a_1x1_bn.bias\n",
      "inception_4b_double_3x3_reduce_bn.running_mean\n",
      "inception_5b_pool_proj_bn.bias\n",
      "inception_4a_3x3_bn.running_var\n",
      "inception_4e_3x3_bn.running_var\n",
      "inception_4b_double_3x3_1_bn.bias\n",
      "inception_3b_double_3x3_1_bn.running_var\n",
      "inception_3c_3x3_reduce_bn.bias\n",
      "inception_4c_double_3x3_2_bn.bias\n",
      "inception_4e_3x3_bn.running_mean\n",
      "inception_4d_1x1_bn.bias\n",
      "inception_3c_3x3_bn.running_var\n",
      "inception_5a_3x3_bn.running_mean\n",
      "inception_3a_1x1_bn.weight\n",
      "inception_4a_double_3x3_reduce_bn.bias\n",
      "inception_3c_3x3_reduce_bn.running_mean\n",
      "inception_4a_double_3x3_2_bn.bias\n",
      "inception_5b_double_3x3_1_bn.bias\n",
      "inception_4c_pool_proj_bn.running_mean\n",
      "conv2_3x3_bn.running_var\n",
      "inception_4d_double_3x3_1_bn.weight\n",
      "inception_4b_3x3_bn.running_mean\n",
      "inception_4d_pool_proj_bn.weight\n",
      "inception_4c_1x1_bn.running_var\n",
      "inception_4b_double_3x3_1_bn.weight\n",
      "inception_3c_3x3_reduce_bn.running_var\n",
      "inception_4b_double_3x3_reduce_bn.weight\n",
      "inception_5a_1x1_bn.running_var\n",
      "inception_3c_double_3x3_2_bn.running_var\n",
      "inception_5b_3x3_bn.weight\n",
      "inception_3b_double_3x3_2_bn.running_var\n",
      "inception_3a_1x1_bn.running_mean\n",
      "inception_5a_3x3_bn.bias\n",
      "inception_5a_double_3x3_1_bn.bias\n",
      "inception_4c_pool_proj_bn.running_var\n",
      "inception_3c_double_3x3_2_bn.weight\n",
      "inception_4e_3x3_reduce_bn.bias\n",
      "inception_4e_double_3x3_reduce_bn.running_mean\n",
      "inception_5a_double_3x3_2_bn.running_var\n",
      "inception_3a_3x3_bn.bias\n",
      "conv1_7x7_s2_bn.running_mean\n",
      "inception_5a_double_3x3_reduce_bn.running_mean\n",
      "inception_4c_double_3x3_2_bn.running_var\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /pytorch/aten/src/THC/generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-79d1b3be19aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mtrain_and_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-79d1b3be19aa>\u001b[0m in \u001b[0;36mtrain_and_val\u001b[0;34m(model_name, split, batch_size, epochs, lr, start_epoch)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mavg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-79d1b3be19aa>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mlabel_arrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_arrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_arrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_new/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_new/lib/python3.5/site-packages/pretrainedmodels/models/bninception.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_new/lib/python3.5/site-packages/pretrainedmodels/models/bninception.py\u001b[0m in \u001b[0;36mfeatures\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mconv1_relu_7x7_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_relu_7x7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1_7x7_s2_bn_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mpool1_3x3_s2_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1_3x3_s2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1_7x7_s2_bn_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mconv2_3x3_reduce_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_3x3_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool1_3x3_s2_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0mconv2_3x3_reduce_bn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_3x3_reduce_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2_3x3_reduce_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mconv2_relu_3x3_reduce_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_relu_3x3_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2_3x3_reduce_bn_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_new/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_new/lib/python3.5/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/aten/src/THC/generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "import pretrainedmodels\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_micro(y_true, y_preds, thresh=0.5, eps=1e-20):\n",
    "    preds_bin = y_preds > thresh # binary representation from probabilities (not relevant)\n",
    "    truepos = preds_bin * y_true\n",
    "    \n",
    "    p = truepos.sum() / (preds_bin.sum() + eps) # take sums and calculate precision on scalars\n",
    "    r = truepos.sum() / (y_true.sum() + eps) # take sums and calculate recall on scalars\n",
    "    \n",
    "    f1 = 2*p*r / (p+r+eps) # we calculate f1 on scalars\n",
    "    return f1\n",
    "\n",
    "def f1_macro(y_true, y_preds, thresh=0.5, eps=1e-20):\n",
    "    preds_bin = y_preds > thresh # binary representation from probabilities (not relevant)\n",
    "    truepos = preds_bin * y_true\n",
    "\n",
    "    p = truepos.sum(axis=0) / (preds_bin.sum(axis=0) + eps) # sum along axis=0 (classes)\n",
    "                                                            # and calculate precision array\n",
    "    r = truepos.sum(axis=0) / (y_true.sum(axis=0) + eps)    # sum along axis=0 (classes) \n",
    "                                                            #  and calculate recall array\n",
    "\n",
    "    f1 = 2*p*r / (p+r+eps) # we calculate f1 on arrays\n",
    "    return np.mean(f1)\n",
    "\n",
    "\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = torch.nn.functional.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.sum(dim=1).mean()\n",
    "\n",
    "def train_and_val(model_name, split, batch_size, epochs, lr, start_epoch):\n",
    "    \n",
    "    model = pretrainedmodels.__dict__[model_name](num_classes = 1000)\n",
    "    num_features = model.last_linear.in_features \n",
    "    model.last_linear = torch.nn.Linear(num_features, 28)\n",
    "    \n",
    "    if model_name == 'polynet':\n",
    "        model = torch.nn.DataParallel(model, device_ids = [0,1,2]).cuda()\n",
    " \n",
    "    \n",
    "    if glob.glob('{}_0*'.format(model_name)):\n",
    "        if model_name == 'vgg19_bn':\n",
    "            pth_file = torch.load('vgg19_bn_0_40.pth.tar')\n",
    "        else:\n",
    "            pth_file = torch.load('{}_0.pth.tar'.format(model_name))\n",
    "        state_dict = pth_file['state_dict']\n",
    "        model.load_state_dict(state_dict)\n",
    "        start_epoch = pth_file['epoch']\n",
    "        \n",
    "    if model_name != 'polynet':\n",
    "        model.cuda()\n",
    "\n",
    "    train_dataset = AtlasData(split = split, train = True, model = model_name)\n",
    "    val_dataset = AtlasData(split = split, train = False, model = model_name)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = 1, shuffle = False)\n",
    "    \n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)   \n",
    "    \n",
    "    \n",
    "    for epoch in range(start_epoch,epochs+1):\n",
    "        \n",
    "        train(model, train_loader, optimizer, criterion, epoch)\n",
    "        avg_loss, f1_score = validate(model, val_loader, criterion, epoch)\n",
    "                    \n",
    "        if epoch % 10 == 0:\n",
    "            filename = '{}_{}_{}.pth.tar'.format(model_name, split, epoch)\n",
    "        else:\n",
    "            filename = '{}_{}.pth.tar'.format(model_name, split)\n",
    "            \n",
    "        state = {'loss': avg_loss, 'f1_score': f1_score, 'epoch': epoch+1, 'state_dict': model.state_dict()}           \n",
    "        torch.save(state, filename)\n",
    "\n",
    "    \n",
    "def train(model, train_loader, optimizer, criterion, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    losses = []\n",
    "    for i, (images, label_arrs, labels) in enumerate(train_loader):\n",
    "        images = images.cuda()\n",
    "        label_arrs = label_arrs.cuda()\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, label_arrs)\n",
    "        losses.append(loss.data[0])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        end = time.time()\n",
    "        elapsed = end-start\n",
    "        \n",
    "        if i%100==0:\n",
    "            print(\"Epoch [{}], Iteration [{}/{}], Loss: {:.4f} ({:.4f}), Elapsed Time {:.4f}\"\n",
    "                .format(epoch, i+1, len(train_loader), loss.data[0], sum(losses)/len(losses), elapsed))\n",
    "            \n",
    "    print(\"Average Loss: {}\".format(sum(losses)/len(losses)))\n",
    "            \n",
    "\n",
    "def validate(model, val_loader, criterion, epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    y_pred = np.zeros(len(val_loader) * 28).reshape(len(val_loader), 28)\n",
    "    y_true = np.zeros(len(val_loader) * 28).reshape(len(val_loader), 28)\n",
    "\n",
    "    for i, (images, label_arrs, labels) in enumerate(val_loader):\n",
    "        images = images.cuda()\n",
    "        label_arrs_cuda = label_arrs.cuda()\n",
    "\n",
    "        raw_predictions = model(images)\n",
    "        outputs = raw_predictions.data\n",
    "        \n",
    "        loss = criterion(outputs, label_arrs_cuda)\n",
    "        losses.append(loss.data)\n",
    "        \n",
    "        predictions = np.arange(28)[raw_predictions.data[0] > 0.15]\n",
    "        \n",
    "        y_pred[i,:] = predictions\n",
    "        y_true[i,:] = label_arrs\n",
    "        \n",
    "        if sum(predictions) == 0:\n",
    "            prediction = np.argmax(raw_predictions.detach().cpu().numpy())\n",
    "            predictions = np.zeros(28)\n",
    "            np.put(predictions, prediction, 1)\n",
    "        \n",
    "        \n",
    "        if i%1000==0:\n",
    "            print('Testing {}/{}: Loss {}'.format(i, \n",
    "                                                 len(val_loader), \n",
    "                                                 sum(losses)/len(losses)))\n",
    "                                                                         \n",
    "    score = f1_macro(y_true, y_pred)\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    print(\"Avg Loss {}\".format(avg_loss))\n",
    "    print(\"Score {}\".format(score))\n",
    "\n",
    "    return avg_loss, score\n",
    "\n",
    "split = 0\n",
    "batch_size = 16\n",
    "epochs = 100\n",
    "lr = 0.0001\n",
    "model_list = [#'xception',\n",
    "#               'se_resnext50_32x4d', \n",
    "#               'nasnetamobile',\n",
    "              'bninception', \n",
    "              'resnet34']\n",
    "\n",
    "start_epoch = 1\n",
    "\n",
    "for model_name in model_list:\n",
    "    print(\"Training {}\".format(model_name))\n",
    "    train_and_val(model_name, split, batch_size, epochs, lr, start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inception_5a_1x1_bn.running_var\n",
      "inception_3c_3x3_bn.running_var\n",
      "inception_4b_pool_proj_bn.bias\n",
      "inception_3b_double_3x3_2_bn.running_var\n",
      "inception_3a_double_3x3_2_bn.weight\n",
      "inception_3b_1x1_bn.bias\n",
      "inception_4b_double_3x3_1_bn.running_mean\n",
      "inception_5b_1x1_bn.bias\n",
      "inception_4d_3x3_reduce_bn.running_mean\n",
      "inception_4a_3x3_reduce_bn.bias\n",
      "inception_3b_double_3x3_2_bn.weight\n",
      "inception_4c_double_3x3_reduce_bn.weight\n",
      "conv2_3x3_reduce_bn.running_var\n",
      "conv1_7x7_s2_bn.weight\n",
      "inception_3b_1x1_bn.running_mean\n",
      "inception_5a_double_3x3_1_bn.weight\n",
      "inception_5b_3x3_reduce_bn.running_var\n",
      "inception_4e_3x3_reduce_bn.running_var\n",
      "inception_4c_double_3x3_1_bn.bias\n",
      "inception_3a_double_3x3_reduce_bn.weight\n",
      "conv1_7x7_s2_bn.running_mean\n",
      "inception_5a_pool_proj_bn.bias\n",
      "inception_4a_double_3x3_reduce_bn.running_mean\n",
      "inception_3a_3x3_reduce_bn.weight\n",
      "inception_4c_double_3x3_1_bn.running_mean\n",
      "inception_3b_pool_proj_bn.weight\n",
      "inception_4c_3x3_bn.running_var\n",
      "inception_3a_3x3_bn.running_mean\n",
      "inception_4a_double_3x3_reduce_bn.bias\n",
      "inception_4c_double_3x3_reduce_bn.running_var\n",
      "inception_3a_1x1_bn.running_var\n",
      "inception_5a_3x3_bn.running_mean\n",
      "inception_4a_double_3x3_1_bn.running_var\n",
      "inception_5b_double_3x3_1_bn.bias\n",
      "inception_4b_3x3_bn.running_var\n",
      "inception_4c_1x1_bn.running_mean\n",
      "inception_4b_3x3_reduce_bn.weight\n",
      "inception_4c_pool_proj_bn.running_mean\n",
      "inception_4d_3x3_bn.bias\n",
      "inception_3c_double_3x3_1_bn.bias\n",
      "inception_3a_double_3x3_1_bn.bias\n",
      "inception_4b_3x3_bn.bias\n",
      "inception_4d_double_3x3_reduce_bn.running_mean\n",
      "inception_5a_1x1_bn.weight\n",
      "inception_5a_pool_proj_bn.weight\n",
      "conv2_3x3_reduce_bn.bias\n",
      "inception_5b_pool_proj_bn.weight\n",
      "inception_3b_double_3x3_1_bn.running_var\n",
      "inception_3c_3x3_reduce_bn.weight\n",
      "inception_3a_3x3_bn.bias\n",
      "inception_3a_double_3x3_2_bn.running_mean\n",
      "inception_4c_1x1_bn.running_var\n",
      "inception_4d_1x1_bn.bias\n",
      "inception_5a_pool_proj_bn.running_var\n",
      "inception_3b_3x3_reduce_bn.weight\n",
      "inception_4e_double_3x3_2_bn.bias\n",
      "inception_4b_3x3_reduce_bn.bias\n",
      "inception_4e_double_3x3_1_bn.weight\n",
      "conv2_3x3_reduce_bn.running_mean\n",
      "inception_4d_3x3_reduce_bn.weight\n",
      "conv2_3x3_bn.weight\n",
      "inception_5b_pool_proj_bn.bias\n",
      "inception_4d_double_3x3_1_bn.running_mean\n",
      "inception_3c_double_3x3_1_bn.running_mean\n",
      "inception_3b_pool_proj_bn.running_mean\n",
      "inception_4d_double_3x3_reduce_bn.running_var\n",
      "inception_3a_3x3_bn.running_var\n",
      "inception_5a_double_3x3_2_bn.weight\n",
      "inception_5b_double_3x3_1_bn.running_var\n",
      "inception_3a_double_3x3_reduce_bn.running_mean\n",
      "inception_4b_double_3x3_reduce_bn.running_mean\n",
      "inception_4d_double_3x3_1_bn.running_var\n",
      "inception_4e_3x3_reduce_bn.weight\n",
      "inception_4a_3x3_reduce_bn.weight\n",
      "inception_5a_double_3x3_reduce_bn.bias\n",
      "inception_5a_3x3_bn.weight\n",
      "inception_4e_double_3x3_reduce_bn.bias\n",
      "inception_5b_pool_proj_bn.running_var\n",
      "inception_3c_3x3_bn.weight\n",
      "inception_5b_double_3x3_reduce_bn.running_mean\n",
      "inception_4c_double_3x3_1_bn.weight\n",
      "inception_4c_double_3x3_reduce_bn.running_mean\n",
      "inception_5b_double_3x3_2_bn.weight\n",
      "inception_3c_3x3_bn.running_mean\n",
      "inception_3a_3x3_reduce_bn.running_var\n",
      "conv1_7x7_s2_bn.bias\n",
      "inception_4a_pool_proj_bn.weight\n",
      "inception_5b_double_3x3_2_bn.bias\n",
      "inception_4c_pool_proj_bn.weight\n",
      "inception_5b_3x3_bn.bias\n",
      "inception_4a_1x1_bn.weight\n",
      "inception_4c_3x3_bn.running_mean\n",
      "inception_5b_double_3x3_2_bn.running_mean\n",
      "inception_5b_double_3x3_1_bn.running_mean\n",
      "inception_3a_double_3x3_reduce_bn.running_var\n",
      "inception_3c_3x3_bn.bias\n",
      "inception_3a_3x3_reduce_bn.bias\n",
      "inception_5b_double_3x3_2_bn.running_var\n",
      "inception_4a_double_3x3_2_bn.running_var\n",
      "inception_3b_double_3x3_1_bn.weight\n",
      "inception_3c_double_3x3_2_bn.running_var\n",
      "inception_3c_double_3x3_reduce_bn.running_var\n",
      "inception_4d_double_3x3_2_bn.running_mean\n",
      "inception_4e_double_3x3_2_bn.weight\n",
      "inception_3b_3x3_reduce_bn.bias\n",
      "inception_4d_double_3x3_2_bn.bias\n",
      "inception_4a_double_3x3_1_bn.bias\n",
      "inception_4d_double_3x3_reduce_bn.weight\n",
      "inception_4a_pool_proj_bn.running_mean\n",
      "inception_3c_3x3_reduce_bn.running_var\n",
      "inception_4a_1x1_bn.bias\n",
      "inception_3c_double_3x3_1_bn.weight\n",
      "inception_5a_double_3x3_1_bn.bias\n",
      "inception_4b_3x3_reduce_bn.running_var\n",
      "inception_3c_double_3x3_reduce_bn.running_mean\n",
      "inception_3a_double_3x3_2_bn.running_var\n",
      "inception_3a_3x3_bn.weight\n",
      "inception_5a_3x3_reduce_bn.running_mean\n",
      "inception_4c_double_3x3_2_bn.weight\n",
      "inception_3b_1x1_bn.running_var\n",
      "inception_5b_3x3_reduce_bn.running_mean\n",
      "inception_4a_double_3x3_1_bn.weight\n",
      "inception_5a_double_3x3_reduce_bn.running_var\n",
      "inception_3b_3x3_bn.running_mean\n",
      "inception_5a_double_3x3_1_bn.running_var\n",
      "inception_4e_3x3_bn.bias\n",
      "inception_4d_3x3_reduce_bn.running_var\n",
      "inception_5a_1x1_bn.running_mean\n",
      "inception_5b_3x3_bn.weight\n",
      "inception_3a_3x3_reduce_bn.running_mean\n",
      "inception_4d_double_3x3_2_bn.weight\n",
      "inception_4d_3x3_bn.running_mean\n",
      "inception_3b_double_3x3_1_bn.bias\n",
      "inception_5b_3x3_bn.running_var\n",
      "inception_3a_pool_proj_bn.running_var\n",
      "inception_4b_double_3x3_2_bn.running_mean\n",
      "inception_4a_pool_proj_bn.bias\n",
      "inception_4d_double_3x3_2_bn.running_var\n",
      "inception_4b_double_3x3_1_bn.weight\n",
      "inception_5b_double_3x3_reduce_bn.bias\n",
      "inception_5a_double_3x3_2_bn.running_var\n",
      "inception_4a_double_3x3_2_bn.running_mean\n",
      "inception_4b_pool_proj_bn.running_var\n",
      "inception_4a_double_3x3_reduce_bn.running_var\n",
      "inception_4a_3x3_reduce_bn.running_var\n",
      "inception_5a_1x1_bn.bias\n",
      "inception_3a_double_3x3_2_bn.bias\n",
      "inception_3c_double_3x3_reduce_bn.bias\n",
      "inception_5b_3x3_reduce_bn.weight\n",
      "inception_3b_double_3x3_reduce_bn.running_var\n",
      "conv2_3x3_bn.running_var\n",
      "inception_4d_1x1_bn.running_var\n",
      "inception_5a_double_3x3_2_bn.running_mean\n",
      "inception_4a_double_3x3_reduce_bn.weight\n",
      "inception_4b_3x3_bn.weight\n",
      "inception_3a_double_3x3_1_bn.weight\n",
      "inception_4e_double_3x3_reduce_bn.running_var\n",
      "inception_3a_pool_proj_bn.weight\n",
      "inception_3c_double_3x3_2_bn.running_mean\n",
      "inception_4a_double_3x3_2_bn.bias\n",
      "inception_3b_3x3_bn.bias\n",
      "inception_4e_3x3_bn.running_var\n",
      "inception_4a_3x3_bn.bias\n",
      "inception_4d_double_3x3_1_bn.bias\n",
      "inception_5b_1x1_bn.running_mean\n",
      "inception_4b_double_3x3_reduce_bn.bias\n",
      "inception_3b_3x3_reduce_bn.running_mean\n",
      "inception_3a_double_3x3_1_bn.running_mean\n",
      "inception_4b_double_3x3_1_bn.running_var\n",
      "inception_4c_3x3_reduce_bn.weight\n",
      "inception_4c_double_3x3_2_bn.running_mean\n",
      "inception_4d_double_3x3_reduce_bn.bias\n",
      "inception_5b_pool_proj_bn.running_mean\n",
      "inception_5a_3x3_reduce_bn.weight\n",
      "inception_4d_pool_proj_bn.running_mean\n",
      "inception_4d_pool_proj_bn.bias\n",
      "inception_4b_pool_proj_bn.running_mean\n",
      "inception_4a_1x1_bn.running_mean\n",
      "inception_5a_3x3_reduce_bn.bias\n",
      "inception_5a_double_3x3_2_bn.bias\n",
      "inception_4d_3x3_reduce_bn.bias\n",
      "inception_4e_double_3x3_1_bn.running_mean\n",
      "inception_3a_1x1_bn.weight\n",
      "inception_3b_double_3x3_2_bn.running_mean\n",
      "inception_4d_3x3_bn.running_var\n",
      "conv2_3x3_bn.running_mean\n",
      "inception_4b_pool_proj_bn.weight\n",
      "inception_4d_3x3_bn.weight\n",
      "inception_4b_double_3x3_2_bn.weight\n",
      "inception_4e_3x3_bn.weight\n",
      "inception_3b_3x3_bn.running_var\n",
      "inception_4d_1x1_bn.running_mean\n",
      "inception_5b_3x3_reduce_bn.bias\n",
      "inception_4b_1x1_bn.running_var\n",
      "inception_4c_double_3x3_2_bn.bias\n",
      "inception_4c_3x3_reduce_bn.running_var\n",
      "inception_4c_1x1_bn.weight\n",
      "inception_4b_double_3x3_2_bn.bias\n",
      "inception_3c_3x3_reduce_bn.running_mean\n",
      "inception_4a_3x3_reduce_bn.running_mean\n",
      "inception_3b_pool_proj_bn.bias\n",
      "inception_3b_pool_proj_bn.running_var\n",
      "inception_4b_double_3x3_reduce_bn.running_var\n",
      "inception_5b_1x1_bn.running_var\n",
      "inception_4e_double_3x3_2_bn.running_mean\n",
      "inception_3a_pool_proj_bn.running_mean\n",
      "inception_4e_3x3_reduce_bn.bias\n",
      "inception_4c_double_3x3_2_bn.running_var\n",
      "conv2_3x3_reduce_bn.weight\n",
      "inception_4b_3x3_reduce_bn.running_mean\n",
      "inception_4e_double_3x3_reduce_bn.running_mean\n",
      "inception_3b_double_3x3_2_bn.bias\n",
      "inception_3a_pool_proj_bn.bias\n",
      "inception_4e_double_3x3_1_bn.running_var\n",
      "inception_4a_double_3x3_1_bn.running_mean\n",
      "inception_3a_1x1_bn.running_mean\n",
      "inception_3c_double_3x3_1_bn.running_var\n",
      "inception_5b_double_3x3_reduce_bn.running_var\n",
      "inception_4a_3x3_bn.running_mean\n",
      "inception_3b_double_3x3_1_bn.running_mean\n",
      "inception_5b_double_3x3_reduce_bn.weight\n",
      "inception_4e_3x3_bn.running_mean\n",
      "inception_4b_double_3x3_2_bn.running_var\n",
      "inception_4c_1x1_bn.bias\n",
      "inception_3a_double_3x3_1_bn.running_var\n",
      "inception_3b_double_3x3_reduce_bn.weight\n",
      "inception_4b_double_3x3_1_bn.bias\n",
      "inception_4e_double_3x3_2_bn.running_var\n",
      "conv1_7x7_s2_bn.running_var\n",
      "inception_4b_3x3_bn.running_mean\n",
      "inception_4c_3x3_bn.weight\n",
      "inception_4c_pool_proj_bn.running_var\n",
      "inception_3c_double_3x3_2_bn.bias\n",
      "inception_3b_3x3_bn.weight\n",
      "inception_4a_pool_proj_bn.running_var\n",
      "inception_4d_double_3x3_1_bn.weight\n",
      "inception_4a_double_3x3_2_bn.weight\n",
      "inception_4a_3x3_bn.weight\n",
      "inception_3b_1x1_bn.weight\n",
      "inception_5a_double_3x3_reduce_bn.running_mean\n",
      "inception_3c_double_3x3_reduce_bn.weight\n",
      "inception_5a_pool_proj_bn.running_mean\n",
      "inception_4c_double_3x3_1_bn.running_var\n",
      "inception_5a_double_3x3_reduce_bn.weight\n",
      "inception_4a_1x1_bn.running_var\n",
      "inception_3c_double_3x3_2_bn.weight\n",
      "inception_4c_3x3_reduce_bn.running_mean\n",
      "inception_3c_3x3_reduce_bn.bias\n",
      "inception_5b_double_3x3_1_bn.weight\n",
      "inception_4b_1x1_bn.weight\n",
      "inception_5a_double_3x3_1_bn.running_mean\n",
      "inception_4c_double_3x3_reduce_bn.bias\n",
      "inception_5a_3x3_bn.running_var\n",
      "inception_4d_pool_proj_bn.running_var\n",
      "inception_4a_3x3_bn.running_var\n",
      "inception_5b_1x1_bn.weight\n",
      "inception_4b_1x1_bn.running_mean\n",
      "inception_4d_1x1_bn.weight\n",
      "inception_3b_double_3x3_reduce_bn.bias\n",
      "inception_4c_pool_proj_bn.bias\n",
      "inception_4c_3x3_reduce_bn.bias\n",
      "inception_3b_double_3x3_reduce_bn.running_mean\n",
      "inception_4c_3x3_bn.bias\n",
      "inception_4e_double_3x3_reduce_bn.weight\n",
      "inception_5b_3x3_bn.running_mean\n",
      "inception_5a_3x3_reduce_bn.running_var\n",
      "inception_4e_3x3_reduce_bn.running_mean\n",
      "inception_5a_3x3_bn.bias\n",
      "conv2_3x3_bn.bias\n",
      "inception_3b_3x3_reduce_bn.running_var\n",
      "inception_3a_1x1_bn.bias\n",
      "inception_4d_pool_proj_bn.weight\n",
      "inception_4b_double_3x3_reduce_bn.weight\n",
      "inception_3a_double_3x3_reduce_bn.bias\n",
      "inception_4b_1x1_bn.bias\n",
      "inception_4e_double_3x3_1_bn.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BNInception(\n",
       "  (conv1_7x7_s2): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (conv1_7x7_s2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (conv1_relu_7x7): ReLU(inplace)\n",
       "  (pool1_3x3_s2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
       "  (conv2_3x3_reduce): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv2_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (conv2_relu_3x3_reduce): ReLU(inplace)\n",
       "  (conv2_3x3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (conv2_relu_3x3): ReLU(inplace)\n",
       "  (pool2_3x3_s2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
       "  (inception_3a_1x1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3a_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_1x1): ReLU(inplace)\n",
       "  (inception_3a_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3a_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_3a_3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3a_3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_3x3): ReLU(inplace)\n",
       "  (inception_3a_double_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3a_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_3a_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3a_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_3a_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3a_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_3a_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_3a_pool_proj): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3a_pool_proj_bn): BatchNorm2d(32, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_pool_proj): ReLU(inplace)\n",
       "  (inception_3b_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3b_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_1x1): ReLU(inplace)\n",
       "  (inception_3b_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3b_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_3b_3x3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3b_3x3_bn): BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_3x3): ReLU(inplace)\n",
       "  (inception_3b_double_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3b_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_3b_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3b_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_3b_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3b_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_3b_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_3b_pool_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3b_pool_proj_bn): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_pool_proj): ReLU(inplace)\n",
       "  (inception_3c_3x3_reduce): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3c_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3c_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_3c_3x3): Conv2d(128, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (inception_3c_3x3_bn): BatchNorm2d(160, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3c_relu_3x3): ReLU(inplace)\n",
       "  (inception_3c_double_3x3_reduce): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3c_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3c_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_3c_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3c_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3c_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_3c_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (inception_3c_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_3c_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_3c_pool): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
       "  (inception_4a_1x1): Conv2d(576, 224, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4a_1x1_bn): BatchNorm2d(224, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_1x1): ReLU(inplace)\n",
       "  (inception_4a_3x3_reduce): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4a_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4a_3x3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4a_3x3_bn): BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_3x3): ReLU(inplace)\n",
       "  (inception_4a_double_3x3_reduce): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4a_double_3x3_reduce_bn): BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4a_double_3x3_1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4a_double_3x3_1_bn): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_4a_double_3x3_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4a_double_3x3_2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_4a_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_4a_pool_proj): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4a_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_pool_proj): ReLU(inplace)\n",
       "  (inception_4b_1x1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4b_1x1_bn): BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_1x1): ReLU(inplace)\n",
       "  (inception_4b_3x3_reduce): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4b_3x3_reduce_bn): BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4b_3x3): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4b_3x3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_3x3): ReLU(inplace)\n",
       "  (inception_4b_double_3x3_reduce): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4b_double_3x3_reduce_bn): BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4b_double_3x3_1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4b_double_3x3_1_bn): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_4b_double_3x3_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4b_double_3x3_2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_4b_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_4b_pool_proj): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4b_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_pool_proj): ReLU(inplace)\n",
       "  (inception_4c_1x1): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4c_1x1_bn): BatchNorm2d(160, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_1x1): ReLU(inplace)\n",
       "  (inception_4c_3x3_reduce): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4c_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4c_3x3): Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4c_3x3_bn): BatchNorm2d(160, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_3x3): ReLU(inplace)\n",
       "  (inception_4c_double_3x3_reduce): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4c_double_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4c_double_3x3_1): Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4c_double_3x3_1_bn): BatchNorm2d(160, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_4c_double_3x3_2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4c_double_3x3_2_bn): BatchNorm2d(160, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_4c_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_4c_pool_proj): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4c_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_pool_proj): ReLU(inplace)\n",
       "  (inception_4d_1x1): Conv2d(608, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4d_1x1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_1x1): ReLU(inplace)\n",
       "  (inception_4d_3x3_reduce): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4d_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4d_3x3): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4d_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_3x3): ReLU(inplace)\n",
       "  (inception_4d_double_3x3_reduce): Conv2d(608, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4d_double_3x3_reduce_bn): BatchNorm2d(160, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4d_double_3x3_1): Conv2d(160, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4d_double_3x3_1_bn): BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_4d_double_3x3_2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4d_double_3x3_2_bn): BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_4d_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_4d_pool_proj): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4d_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_pool_proj): ReLU(inplace)\n",
       "  (inception_4e_3x3_reduce): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4e_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4e_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4e_3x3): Conv2d(128, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (inception_4e_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4e_relu_3x3): ReLU(inplace)\n",
       "  (inception_4e_double_3x3_reduce): Conv2d(608, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4e_double_3x3_reduce_bn): BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4e_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4e_double_3x3_1): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4e_double_3x3_1_bn): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4e_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_4e_double_3x3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (inception_4e_double_3x3_2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_4e_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_4e_pool): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
       "  (inception_5a_1x1): Conv2d(1056, 352, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5a_1x1_bn): BatchNorm2d(352, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_1x1): ReLU(inplace)\n",
       "  (inception_5a_3x3_reduce): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5a_3x3_reduce_bn): BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_5a_3x3): Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_5a_3x3_bn): BatchNorm2d(320, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_3x3): ReLU(inplace)\n",
       "  (inception_5a_double_3x3_reduce): Conv2d(1056, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5a_double_3x3_reduce_bn): BatchNorm2d(160, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_5a_double_3x3_1): Conv2d(160, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_5a_double_3x3_1_bn): BatchNorm2d(224, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_5a_double_3x3_2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_5a_double_3x3_2_bn): BatchNorm2d(224, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_5a_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_5a_pool_proj): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5a_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_pool_proj): ReLU(inplace)\n",
       "  (inception_5b_1x1): Conv2d(1024, 352, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5b_1x1_bn): BatchNorm2d(352, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_1x1): ReLU(inplace)\n",
       "  (inception_5b_3x3_reduce): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5b_3x3_reduce_bn): BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_5b_3x3): Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_5b_3x3_bn): BatchNorm2d(320, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_3x3): ReLU(inplace)\n",
       "  (inception_5b_double_3x3_reduce): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5b_double_3x3_reduce_bn): BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_5b_double_3x3_1): Conv2d(192, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_5b_double_3x3_1_bn): BatchNorm2d(224, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_5b_double_3x3_2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_5b_double_3x3_2_bn): BatchNorm2d(224, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_5b_pool): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), ceil_mode=True)\n",
       "  (inception_5b_pool_proj): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5b_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_pool_proj): ReLU(inplace)\n",
       "  (global_pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (last_linear): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pretrainedmodels.__dict__['bninception']()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalAtlasData(Dataset):\n",
    "    def __init__(self, model = 'bninception'):\n",
    "        self.image_ids = sorted(set([x.split('_')[0] for x in os.listdir('data/test')]))\n",
    "        \n",
    "        self.input_size = model_configs[model]['input_size']\n",
    "        self.input_mean = model_configs[model]['input_mean']\n",
    "        self.input_std = model_configs[model]['input_std']\n",
    "        \n",
    "        self.transforms = transforms.Compose([transforms.Resize(self.input_size),\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize(self.input_mean, self.input_std),\n",
    "                                            ])\n",
    "        \n",
    "        \n",
    "    def load_image_stack(self, image_id):\n",
    "        colors = ['red', 'green', 'blue', 'yellow']\n",
    "        absolute_paths = [\"data/test/{}_{}.png\".format(image_id, color) for color in colors]\n",
    "        \n",
    "        images = [skimage.io.imread(path) for path in absolute_paths]\n",
    "        \n",
    "        image_red = images[0]\n",
    "        image_green = images[1] + (images[3]/2).astype(np.uint8)\n",
    "        image_blue = images[2] + (images[3]/2).astype(np.uint8)\n",
    "        \n",
    "        final_image = np.stack((image_red, image_green, image_blue), -1)\n",
    "        to_display = Image.fromarray(final_image)\n",
    "        return to_display\n",
    "    \n",
    "    def dump_image(self, i):\n",
    "        image = self.load_image_stack(self.image_ids[i])\n",
    "        image_name = \"data/test/{}_{}.png\".format(self.image_ids[i], 'stacked')\n",
    "        image.save(image_name)\n",
    "        print(\"Saved\", image_name)\n",
    "        \n",
    "    def load_image(self, i):\n",
    "        image_id = self.image_ids[i]\n",
    "        image_path = \"data/test/{}_{}.png\".format(image_id, 'stacked')\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        return image, image_id\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        image, image_id = self.load_image(i)\n",
    "        image = self.transforms(image)\n",
    "        \n",
    "        return image_id, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pretrainedmodels\n",
    "import pandas as pd\n",
    "from torch.nn import Softmax\n",
    "\n",
    "def generate_preds(model_name):\n",
    "    model = pretrainedmodels.__dict__[model_name](num_classes = 1000, pretrained = 'imagenet')\n",
    "    in_features = model.last_linear.in_features\n",
    "    model.last_linear = torch.nn.Linear(in_features, 28)\n",
    "    \n",
    "    if model_name == 'polynet':\n",
    "        model = torch.nn.DataParallel(model, device_ids = [0,1,2,3]).cuda()\n",
    "        model.load_state_dict(torch.load('{}_0.pth.tar'.format(model_name)))\n",
    "        model = model.eval()\n",
    "    else:\n",
    "        model.load_state_dict(torch.load('{}_0.pth.tar'.format(model_name)))\n",
    "        model = model.eval()\n",
    "        model.cuda()\n",
    "\n",
    "    eval_data = EvalAtlasData(model = model_name)\n",
    "    dataloader = DataLoader(eval_data, 1, False)\n",
    "    \n",
    "    preds = []\n",
    "    for i, (image_id, images) in enumerate(dataloader):\n",
    "        images = images.cuda()\n",
    "\n",
    "        raw_predictions = (model(images))\n",
    "        predictions = np.argwhere(raw_predictions.data[0] > 0.15)\n",
    "        try:\n",
    "            num_predictions = len(predictions.data[0])\n",
    "        except IndexError:\n",
    "            num_predictions = 0\n",
    "\n",
    "        print('-----------------------------------------------------')\n",
    "        print(image_id[0])\n",
    "        print('Raw Prediction', raw_predictions)\n",
    "        if num_predictions == 0:\n",
    "            print('No value passed the threshold')\n",
    "            predictions = [np.argmax(raw_predictions.detach().cpu().numpy())]\n",
    "            num_predictions = 1\n",
    "            print(\"Prediction:\", predictions)\n",
    "            print(\"Number of predictions\", num_predictions)\n",
    "        else:\n",
    "            predictions = predictions.data[0].tolist()\n",
    "            print(\"Prediction:\", predictions)\n",
    "            print(\"Number of predictions\", num_predictions)\n",
    "\n",
    "        predicted = ' '.join('%d' % prediction for prediction in predictions)\n",
    "        print(image_id[0])\n",
    "        print(predicted)\n",
    "        pred = dict(Id = image_id[0], Predicted = predicted)\n",
    "        preds.append(pred)\n",
    "        \n",
    "    df = pd.DataFrame(preds)\n",
    "    df.to_csv('{}.csv'.format(model_name), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_configs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-25b770dd8c62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'polynet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-35df5a6b3661>\u001b[0m in \u001b[0;36mgenerate_preds\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0meval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvalAtlasData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d56f387ee55f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_std'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_configs' is not defined"
     ]
    }
   ],
   "source": [
    "generate_preds('polynet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "baha = \"_features.0.weight\", \"_features.0.bias\", \"_features.1.weight\", \"_features.1.bias\", \"_features.1.running_mean\", \"_features.1.running_var\", \"_features.3.weight\", \"_features.3.bias\", \"_features.4.weight\", \"_features.4.bias\", \"_features.4.running_mean\", \"_features.4.running_var\", \"_features.7.weight\", \"_features.7.bias\", \"_features.8.weight\", \"_features.8.bias\", \"_features.8.running_mean\", \"_features.8.running_var\", \"_features.10.weight\", \"_features.10.bias\", \"_features.11.weight\", \"_features.11.bias\", \"_features.11.running_mean\", \"_features.11.running_var\", \"_features.14.weight\", \"_features.14.bias\", \"_features.15.weight\", \"_features.15.bias\", \"_features.15.running_mean\", \"_features.15.running_var\", \"_features.17.weight\", \"_features.17.bias\", \"_features.18.weight\", \"_features.18.bias\", \"_features.18.running_mean\", \"_features.18.running_var\", \"_features.20.weight\", \"_features.20.bias\", \"_features.21.weight\", \"_features.21.bias\", \"_features.21.running_mean\", \"_features.21.running_var\", \"_features.23.weight\", \"_features.23.bias\", \"_features.24.weight\", \"_features.24.bias\", \"_features.24.running_mean\", \"_features.24.running_var\", \"_features.27.weight\", \"_features.27.bias\", \"_features.28.weight\", \"_features.28.bias\", \"_features.28.running_mean\", \"_features.28.running_var\", \"_features.30.weight\", \"_features.30.bias\", \"_features.31.weight\", \"_features.31.bias\", \"_features.31.running_mean\", \"_features.31.running_var\", \"_features.33.weight\", \"_features.33.bias\", \"_features.34.weight\", \"_features.34.bias\", \"_features.34.running_mean\", \"_features.34.running_var\", \"_features.36.weight\", \"_features.36.bias\", \"_features.37.weight\", \"_features.37.bias\", \"_features.37.running_mean\", \"_features.37.running_var\", \"_features.40.weight\", \"_features.40.bias\", \"_features.41.weight\", \"_features.41.bias\", \"_features.41.running_mean\", \"_features.41.running_var\", \"_features.43.weight\", \"_features.43.bias\", \"_features.44.weight\", \"_features.44.bias\", \"_features.44.running_mean\", \"_features.44.running_var\", \"_features.46.weight\", \"_features.46.bias\", \"_features.47.weight\", \"_features.47.bias\", \"_features.47.running_mean\", \"_features.47.running_var\", \"_features.49.weight\", \"_features.49.bias\", \"_features.50.weight\", \"_features.50.bias\", \"_features.50.running_mean\", \"_features.50.running_var\", \"linear0.weight\", \"linear0.bias\", \"linear1.weight\", \"linear1.bias\", \"last_linear.weight\", \"last_linear.bias\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumbray = list(baha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load('vgg19_bn_0.pth.tar')\n",
    "state_dict = state['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cum in cumbray:\n",
    "    state_dict[cum] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['state_dict'] = state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(state, 'vgg19_bn_0.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "\n",
    "1. Use Focal Loss https://www.kaggle.com/iafoss/pretrained-resnet34-with-rgby-fast-ai\n",
    "2. Somehow use the Y channel\n",
    "\n",
    "Trained:\n",
    "1. InceptionV4 100 epochs\n",
    "2. SE-ResNext 33 epochs\n",
    "3. PolyNet 33 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for VGG:\n\tUnexpected key(s) in state_dict: \"_features.0.weight\", \"_features.0.bias\", \"_features.1.weight\", \"_features.1.bias\", \"_features.1.running_mean\", \"_features.1.running_var\", \"_features.3.weight\", \"_features.3.bias\", \"_features.4.weight\", \"_features.4.bias\", \"_features.4.running_mean\", \"_features.4.running_var\", \"_features.7.weight\", \"_features.7.bias\", \"_features.8.weight\", \"_features.8.bias\", \"_features.8.running_mean\", \"_features.8.running_var\", \"_features.10.weight\", \"_features.10.bias\", \"_features.11.weight\", \"_features.11.bias\", \"_features.11.running_mean\", \"_features.11.running_var\", \"_features.14.weight\", \"_features.14.bias\", \"_features.15.weight\", \"_features.15.bias\", \"_features.15.running_mean\", \"_features.15.running_var\", \"_features.17.weight\", \"_features.17.bias\", \"_features.18.weight\", \"_features.18.bias\", \"_features.18.running_mean\", \"_features.18.running_var\", \"_features.20.weight\", \"_features.20.bias\", \"_features.21.weight\", \"_features.21.bias\", \"_features.21.running_mean\", \"_features.21.running_var\", \"_features.23.weight\", \"_features.23.bias\", \"_features.24.weight\", \"_features.24.bias\", \"_features.24.running_mean\", \"_features.24.running_var\", \"_features.27.weight\", \"_features.27.bias\", \"_features.28.weight\", \"_features.28.bias\", \"_features.28.running_mean\", \"_features.28.running_var\", \"_features.30.weight\", \"_features.30.bias\", \"_features.31.weight\", \"_features.31.bias\", \"_features.31.running_mean\", \"_features.31.running_var\", \"_features.33.weight\", \"_features.33.bias\", \"_features.34.weight\", \"_features.34.bias\", \"_features.34.running_mean\", \"_features.34.running_var\", \"_features.36.weight\", \"_features.36.bias\", \"_features.37.weight\", \"_features.37.bias\", \"_features.37.running_mean\", \"_features.37.running_var\", \"_features.40.weight\", \"_features.40.bias\", \"_features.41.weight\", \"_features.41.bias\", \"_features.41.running_mean\", \"_features.41.running_var\", \"_features.43.weight\", \"_features.43.bias\", \"_features.44.weight\", \"_features.44.bias\", \"_features.44.running_mean\", \"_features.44.running_var\", \"_features.46.weight\", \"_features.46.bias\", \"_features.47.weight\", \"_features.47.bias\", \"_features.47.running_mean\", \"_features.47.running_var\", \"_features.49.weight\", \"_features.49.bias\", \"_features.50.weight\", \"_features.50.bias\", \"_features.50.running_mean\", \"_features.50.running_var\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-75f7c9ca9e8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_linear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vgg19_bn_0_40.pth.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/pytorch_new/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 721\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for VGG:\n\tUnexpected key(s) in state_dict: \"_features.0.weight\", \"_features.0.bias\", \"_features.1.weight\", \"_features.1.bias\", \"_features.1.running_mean\", \"_features.1.running_var\", \"_features.3.weight\", \"_features.3.bias\", \"_features.4.weight\", \"_features.4.bias\", \"_features.4.running_mean\", \"_features.4.running_var\", \"_features.7.weight\", \"_features.7.bias\", \"_features.8.weight\", \"_features.8.bias\", \"_features.8.running_mean\", \"_features.8.running_var\", \"_features.10.weight\", \"_features.10.bias\", \"_features.11.weight\", \"_features.11.bias\", \"_features.11.running_mean\", \"_features.11.running_var\", \"_features.14.weight\", \"_features.14.bias\", \"_features.15.weight\", \"_features.15.bias\", \"_features.15.running_mean\", \"_features.15.running_var\", \"_features.17.weight\", \"_features.17.bias\", \"_features.18.weight\", \"_features.18.bias\", \"_features.18.running_mean\", \"_features.18.running_var\", \"_features.20.weight\", \"_features.20.bias\", \"_features.21.weight\", \"_features.21.bias\", \"_features.21.running_mean\", \"_features.21.running_var\", \"_features.23.weight\", \"_features.23.bias\", \"_features.24.weight\", \"_features.24.bias\", \"_features.24.running_mean\", \"_features.24.running_var\", \"_features.27.weight\", \"_features.27.bias\", \"_features.28.weight\", \"_features.28.bias\", \"_features.28.running_mean\", \"_features.28.running_var\", \"_features.30.weight\", \"_features.30.bias\", \"_features.31.weight\", \"_features.31.bias\", \"_features.31.running_mean\", \"_features.31.running_var\", \"_features.33.weight\", \"_features.33.bias\", \"_features.34.weight\", \"_features.34.bias\", \"_features.34.running_mean\", \"_features.34.running_var\", \"_features.36.weight\", \"_features.36.bias\", \"_features.37.weight\", \"_features.37.bias\", \"_features.37.running_mean\", \"_features.37.running_var\", \"_features.40.weight\", \"_features.40.bias\", \"_features.41.weight\", \"_features.41.bias\", \"_features.41.running_mean\", \"_features.41.running_var\", \"_features.43.weight\", \"_features.43.bias\", \"_features.44.weight\", \"_features.44.bias\", \"_features.44.running_mean\", \"_features.44.running_var\", \"_features.46.weight\", \"_features.46.bias\", \"_features.47.weight\", \"_features.47.bias\", \"_features.47.running_mean\", \"_features.47.running_var\", \"_features.49.weight\", \"_features.49.bias\", \"_features.50.weight\", \"_features.50.bias\", \"_features.50.running_mean\", \"_features.50.running_var\". "
     ]
    }
   ],
   "source": [
    "import pretrainedmodels\n",
    "import torch\n",
    "\n",
    "model = pretrainedmodels.__dict__['vgg19_bn']()\n",
    "in_features = model.last_linear.in_features\n",
    "\n",
    "model.last_linear = torch.nn.Linear(in_features, 28)\n",
    "model.cuda()\n",
    "model.load_state_dict(torch.load('vgg19_bn_0_40.pth.tar')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
